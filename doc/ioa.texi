\input texinfo  @c -*-texinfo-*-
@c %** Start of header
@setfilename ioa.info
@settitle ioa++
@setchapternewpage odd
@c %** End of header

@include version.texi

@copying
This manual is for ioa++, version @value{VERSION}.

Copyright @copyright{} 2011 Justin R. Wilson.

@quotation
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
@end quotation
@end copying

@titlepage
@title ioa++
@author Justin R. Wilson

@c The following two commands start the copyright page.
@page
@vskip 0pt plus 1filll
@insertcopying

@end titlepage

@c So the TOC is printed in the right place.
@contents

@ifnottex
@node Top
@top ioa++

This manual describes version @value{VERSION} of ioa++.

@insertcopying

@end ifnottex

@menu
* Introduction::                Tutorial sections:
* Examples::                    Reference sections:
* Reference::                   
* Copying::                     
@end menu

@node Introduction
@chapter Introduction

ioa++ is a general-purpose framework for developing asynchronous and concurrent programs based on the I/O automata model.
Developers using ioa++ construct programs by defining and assembling event-based modules called I/O automata to form interacting constellations.
As suggested by the name, ioa++ is implemented in C++.

@section The I/O Automata Model

The I/O automata model was developed by Nancy Lynch for asynchronous and concurrent systems and is described in Chapter 8 of @cite{Distributed Algorithms}.
I/O automata have been used to model and verify a number of real-world systems and protocols.

An I/O automaton consists of state variables and a set of atomic input, output, and internal actions.
The set of actions in an automaton is known as its @dfn{signature}.
Output and internal actions constitute the automaton's @dfn{local signature}.
Local actions have a predicate over the state variables of the automaton (called a @dfn{precondition}) that indicates if the action can be executed.
All actions have an @dfn{effect} which updates the state variables of the corresponding automaton.
Input and output actions constitute the automaton's @dfn{external signature}.

I/O automata can be composed to form a new automaton by concatenating state variables and folding input actions into similarly named output actions.
Whereas local actions can be @dfn{enabled} or @dfn{disabled} based on their precondition, input actions are executed whenever their associated output is executed.
This property is known as being @dfn{input enabled}.

Execution proceeds by repeatedly selecting a local action and executing it if enabled.
The model admits non-determinism by allowing the scheduler to pick actions in any order.
Schedulers in I/O automata must be @dfn{fair} meaning they select (but do not necessarily execute) every action infinitely often.

@section Representing I/O Automata

I/O automata are encoded directly in the C++ programming language as classes that inherit from @code{ioa::automaton}.
The state variables of the I/O automaton are naturally encoded as member variables of the class.
The actions of the I/O automaton are encoded as a combination of member functions and member variables.
A suite of templates and macros exist to simplify the definition of actions.

@section Dynamics

The I/O automata model assumes that systems consist of a static set of automata.
Often, the size of the set is countably infinite meaning that it can be represented by an integer variable @var{N}.
A model specified in this way is capable of capturing any real system since there is a countable number of participants in all real systems.
Within an countably infinite set, a dynamic set of automata is simulated by associating a flag with each automaton indicating if it is active or inactive and defining appropriate ``wake-up'' and ``sleep'' actions.
A direct implementation of this strategy does not work for real systems because an implementation must specify a concrete value for @var{N}.
Computing with a fixed number of automata is either unduly prohibitive if resources exist for additional automata or unduly wasteful if the number of active automata is much less than @var{N}.

Consequently, we require the ability to dynamically create and destroy automata.
An automaton that creates another automaton is called the @dfn{parent} while the created automaton is called the @dfn{child}.
The automaton at the top of the hierarchy is called the @dfn{root}.
Since we can dynamically create and destroy automata, we also require the ability to dynamically compose and decompose.
@dfn{Binding} and @dfn{unbinding} refer to the act of dynamically composing and decomposing, respectively.
For simplicity, binding and unbinding is limited to a single output action-input action pair.
Explicit binding allows us to drop the requirement that the actions have the same name.

@section Run-time System

The ioa++ run-time system consists of a system automaton, a dispatcher, a scheduler, and a user-space library.

The @dfn{system automaton} contains the set of automata and bindings that exist in the system and actions for creating, binding, unbinding, and destroying.
These actions are collectively called @dfn{system actions}.
Each automaton is @emph{composed} with the system automaton by inheriting from @code{ioa::automaton}.

The @dfn{dispatcher} enforces atomic execution according to the I/O automata model.
Internal actions are executed by evaluating the precondition and then applying the effect if the precondition is true.
The precondition and effect are computed in one atomic step.
Output actions are executed similarly except that all bound input actions are evaluated atomically with the output action.

The @dfn{scheduler} selects the next action from a set of local actions.
The set of local actions is updated by the automata in the system via @code{ioa::schedule} calls.
Different schedulers can be used to realize different scheduling policies.

The user-space library is designed to help users write actions, schedule actions, and request system actions.
Local actions consist of an object and three functions: a precondition, an effect, and a scheduling function.
Input actions consists of an object and two functions: an effect and a scheduling function.
The scheduling function is invoked after the effect of all actions and is intended as a place to schedule actions.
The user-space library also contains classes that hide the complexities of creating and binding asynchronously.

@section Concurrency

Each local action involves a set of automata.
For internal actions, this is just the automaton that contains the internal actions.
For output actions, the set consists of the output action and the automata that contain the input actions bound to the output action.
The semantics of I/O automata are such that two actions can be executed concurrently if their respective sets of involved automata are disjoint.
An important consequence is that two actions belonging to the same automaton will never execute concurrently.
True concurrent execution requires a scheduler capable of true concurrent execution, i.e., a multi-threaded scheduler.

@section Actions and Values

Recall that there are three types of actions: output actions, input actions, and internal actions.
Output actions produce a signal or value, input actions consume a signal or value, and internal actions neither produce nor consume signals or values.
Actions that produce or consume signals are said to be @dfn{unvalued} while signals that produce and consume values are said to be @dfn{valued}.
External actions can only be bound together if they agree on the signal or type of value to be produced.
Any input that consumes a signal can be bound to any output producing a signal.
An input that consumes values of type @var{T} can only be bound to an output that produces a value of type @var{T}.

@section Parameters and Automatic Parameters

A common technique in the I/O automata model is to associate a parameter with an action.
For example, actions that receive messages are often parameterized with communication endpoints.
Parameters are distinct from values because they are constant under composition.
All actions types, outputs, inputs, and internals, can be parameterized.
Actions requiring a parameter are said to be @dfn{parameterized} while actions that don't require parameters are said to be @dfn{unparameterized}.
Parameters must be used to identify parameterized actions.
For example, the parameter for a parameterized output must specified when scheduling and binding.
Similarly, a parameter for a parameterized input must specified when binding and a parameter for a parameterized internal must be specified when scheduling.

Parameters allow users to implement fan-in by associating a different parameter with each bind to an input.
More generally, parameters can be used to implement a session by associating the same parameter with all bindings related to some automaton.
Each automaton has a unique identifier called an @dfn{automaton identfier} or @dfn{aid}.
Often, the parameter for a session is the aid of another automaton.
To prevent errors and make sessions easier to implement, we introduce the concept of an automatic parameter.
An @dfn{automatic parameter} or @dfn{auto parameter} is a parameter that represents the automaton on the opposite side of a binding.
For example, an auto parameterized input bears the identifier of the output automaton to which it is bound.
An auto parameterized output bears the identifier of the input automaton to which it is bound.
According to the binding rules below, auto parameterized outputs can only be bound once.

@section Binding Rules

To enforce the semantics of I/O automata, certain attempts to bind will fail.
The automaton requesting a binding is called the @dfn{owner}.
A binding is a tuple (output automaton, output action, output parameter, input automaton, input action, input parameter, owner).
Unparameterized actions have a null parameter.
A binding will fail if any of the following conditions is true:
@enumerate
@item The owner does not exist.
@item The output automaton does not exist.
@item The input automaton does not exist.
@item The binding already exists.  (This is only reported to the owner.)
@item The (input automaton, input action, input parameter) is already bound.
@item The (output automaton, output action, output parameter) is already bound to some input action in the input automaton.
@item The output automaton and input automaton are the same.
@end enumerate

@node Examples
@chapter Examples

@menu
* Compiling and Linking::       
* Internal Actions::            
* Creating Automata::           
* External Actions::            
* Fan-out and Binding Count::   
@end menu

@node Compiling and Linking
@section Compiling and Linking

The purpose of this tutorial is to introduce the necessary machinery for compiling programs with ioa++.
The following program contains the null automaton---an automaton with no actions.
The source can be found in @file{tutorial/null_automaton.cpp}.

@example
@verbatiminclude tutorial/null_automaton.cpp
@end example

Let's go through it section by section.
The lines
@example
@verbatim
#include <ioa/ioa.hpp>
#include <ioa/global_fifo_scheduler.hpp>
@end verbatim
@end example
include all of the headers necessary for writing I/O automata and the header needed to declare a global FIFO scheduler.
The lines
@example
@verbatim
class null_automaton :
  public ioa::automaton
{ };
@end verbatim
@end example
declare a new automaton type called @code{null_automaton}.
All automata must inherit from @code{ioa::automaton}.
Also note that all ioa++ types and functions are in the @code{ioa} namespace.
The main function
@example
@verbatim
int main () {
  ioa::global_fifo_scheduler sched;
  ioa::run (sched, ioa::make_generator<null_automaton> ());
  return 0;
}
@end verbatim
@end example
declares a new scheduler @code{sched} and starts the scheduler with a new root automaton of type @code{null_automaton}.
The @code{run} function takes two arguments: a scheduler and an allocator.
An allocator is an object that can later be invoked to produce a dynamically allocated object.
In this case, the allocator returns a dynamically created instance of @code{null_automaton}.

Assuming that a copy of @file{null_automaton.cpp} exists in the current directory and that @command{g++} is your C++ compiler, one can compile and run the null automaton with
@example
@verbatim
$ g++ null_automaton.cpp -o null_automaton -lioa -lpthread
$ ./null_automaton
@end verbatim
@end example
Notice that we needed to link against the I/O automata library (@option{-lioa}) and pthreads library (@option{-lpthread}).
Some environments, e.g., Mac OS X, include pthreads in the standard C library.
If you have such an environment, omit the @option{-lpthread} part of the command.

@node Internal Actions
@section Internal Actions

In this tutorial we develop an automaton that counts to ten using an internal action.
The source is given below and can be found in @file{tutorial/count_to_ten_automaton.cpp}.

@example
@verbatiminclude tutorial/count_to_ten_automaton.cpp
@end example

The automata in this tutorial are listed in a way that attempts to mimic the style in @cite{Distributed Algorithms}.
In general, an automaton will have the following structure:
@itemize

@item Type definitions --- Declare types that are used internally by the automaton and types that are used by external actions.

@item State declarations --- Declare the state variables of the automaton.

@item Constructors/Destructors --- Declare/define constructors to initialize the state variables and destructors to perform any required clean-up.

@item Private member functions --- Declare/define useful functions.

@item Actions --- Declare/define the actions of the automaton.  Local actions consist of a precondition, an effect, a scheduling function, and a member variable.  Input actions consist of an effect, a scheduling function, and a member variable.

@end itemize

Let's examine the automaton section by section.
The state of the automaton is declared with
@example
@verbatim
private:
  int m_count;
@end verbatim
@end example
In this case, the state of the automaton consists of a single integer @code{m_count}.
State variables should always be declared @code{private}.

The constructor initializes the count to 1 and calls the @code{increment_schedule} member function to tell the scheduler to select the @code{increment} action:
@example
@verbatim
public:
  count_to_ten_automaton () :
    m_count (1) {
    increment_schedule ();
  }
@end verbatim
@end example

The next section defines the precondition, effect, and scheduling function for an unparameterized internal action named @code{increment}:
@example
@verbatim
  bool increment_precondition () const {
    return m_count <= 10;
  }

  void increment_effect () {
    std::cout << m_count << std::endl;
    ++m_count;
  }

  void increment_schedule () const {
    if (increment_precondition ()) {
      ioa::schedule (&count_to_ten_automaton::increment);
    }
  }
@end verbatim
@end example
Following the style in @cite{Distributed Algorithms}, internal actions are divided into a @dfn{precondition} and @dfn{effect}.
The precondition returns a @code{bool} indicating if the action can be executed.
In this example, the precondition returns true so long as the count is less than or equal to ten.
The pattern for declaring the precondition for an unparameterized internal actions is @code{bool @var{action-name}_precondition () const;}.
Note that preconditions have the @code{const} modifier as they should not change the state of the automaton.
The effect changes the state of the automaton.
In this example, the effect prints the current value of the count and increments the count.
The pattern for declaring the effect of an unparameterized internal action is @code{void @var{action-name}_effect ();}.
The scheduling function is called after the effect and it used to tell the scheduler about actions that should be selected.
In this example, the @code{increment} action is scheduled if its precondition is true.
The pattern for declaring a scheduling fuctions is @code{void @var{action-name}_schedule () const;}.
Preconditions, effects, and scheduling functions should always be declared @code{private}.

The final part of declaring/defining an unparameterized internal action is to declare a member variable representing the action that dispatches to the precondition, effect, and scheduling function and also contains appropriate typedefs for the scheduler.
This is tedious so a set of a macros is defined to simplify declaring the members.
The code
@example
@verbatim
  UP_INTERNAL (count_to_ten_automaton, increment);
@end verbatim
@end example
uses the @code{UP_INTERNAL} macro to declare an action member variable @code{increment}.
The @code{UP_INTERNAL} macro and similar macros rely on the @code{*_precondition}, @code{*_action}, and @code{*_schedule} naming convention described earlier.
The macro arranges for the @code{*_schedule} member function to be called after each action effect.
Internal actions, i.e., the scope where @code{UP_INTERNAL} appears, should be @code{private}.
External actions can either be @code{private}, @code{protected}, or @code{public} depending on their intended use.

To summarize, consider the uses of the automaton name and action names.
To declare an automaton:
@example
@code{class @var{automaton-name} : public ioa::automaton @enddots{}}
@end example
To declare a precondition for an unparameterized internal action:
@example
@code{bool @var{action-name}_precondition () const;}
@end example
To declare a effect for an unparameterized internal action:
@example
@code{void @var{action-name}_effect ();}
@end example
To declare a scheduling function:
@example
@code{void @var{action-name}_schedule () const;}
@end example
To declare an unparameterized internal action:
@example
@code{UP_INTERNAL (@var{automaton-name}, @var{action-name});}
@end example
To schedule an unparameterized local action:
@example
@code{ioa::schedule (&@var{automaton-name}::@var{action-name});}
@end example

@strong{Programming Tip:}
Forgetting to schedule is common source of problems when programming with ioa++.
Remember to call @code{ioa::schedule} for all enabled local actions in the constructor and scheduling functions (or effects).
As an exercise, experiment with commenting out the call to @code{increment_schedule} in the constructor and the call to @code{ioa::schedule} in @code{increment_schedule}.

@node Creating Automata
@section Creating Automata

Decomposition is a powerful technique for managing complexity---especially in concurrent and distributed systems.
Instead of solving the problem with one large automaton, we can decompose the problem into a number of simpler automata and bind their actions together.
Additionally, decomposition also allows us to find generic components that can be reused for many problems.

In this tutorial we develop an automaton that creates two @code{count_to_ten_automaton}s.
Binding actions will be covered later when we cover input and output actions.
The source is given below and can be found in @file{tutorial/two_counters.cpp}.

@example
@verbatiminclude tutorial/two_counters.cpp
@end example

This example contains two automata: @code{count_to_ten_automaton} and @code{two_counter_automaton}.
Of primary interest is the constructor of the @code{two_counter_automaton}.
@example
@verbatim
  two_counter_automaton () {
    ioa::make_automaton_manager (this,
        ioa::make_generator<count_to_ten_automaton> ());
    ioa::make_automaton_manager (this,
	ioa::make_generator<count_to_ten_automaton> ());
  }
@end verbatim
@end example
The function @code{ioa::make_automaton_manager} creates a dynamically allocated @code{ioa::automaton_manager}.
An @code{ioa::automaton_manager} uses an @code{ioa::automaton} object and generator to @emph{asynchronously} create a new automaton.
@emph{Automaton creation and destruction are asynchronous in ioa++.}
A pointer to an @code{ioa::automaton} object is specified by the first argument to the @code{ioa::make_automaton_manager} function.
This should always be the @code{this} pointer of the automaton that is creating a new automaton.
The second argument is a generator that returns an instance of the automaton to be created.
In this example, each generator returns a @code{count_to_ten} automaton.

If automaton A creates automaton B then A is the @dfn{parent} of B and B is the @dfn{child} of A.
Thus, automata in ioa++ form a tree with the automaton generated by @code{ioa::run} being the root.
When an automaton is destroyed, so are all of its children.

Something that might concern you is that fact that the automaton managers are dynamically allocated but we neither save their address nor @code{delete} them in a destructor.
Upon construction, the @code{ioa::automaton} object takes ownership of the automaton manager.
A parent automaton can request that one of its children be destroyed using its @code{destroy} method and can detect child automata that have been destroyed by observing the automaton manager.
Note that a child automaton might voluntarily destroy itself, i.e., self destruct, when it has no more work to do.
A parent automaton should forget the automaton manager of any child that has been destroyed.

To distinguish the output of the two @code{count_to_ten_automaton}s, we use the @code{ioa::get_aid} function.
@example
@verbatim
    std::cout <<
      "automaton: " << ioa::get_aid () <<
      " count: " << m_count << std::endl;
@end verbatim
@end example
Associated with each instance of an automaton is an @dfn{automaton identifier (aid)} of type @code{aid_t} that can be retrieved with @code{ioa::get_aid}.

@node External Actions
@section External Actions

In this tutorial, we introduce input and output actions and the concept of binding using a simple producer-consumer problem.
We split the @code{count_to_ten_automaton} in previous tutorials into an automaton that produces numbers and another automaton that prints numbers.
The source is given below and can be found in @file{tutorial/producer_consumer.cpp}.

@example
@verbatiminclude tutorial/producer_consumer.cpp
@end example

The first part of the @code{producer_automaton} resembles the @code{count_to_ten_automaton} in previous tutorials where we have renamed the @code{increment} action to @code{produce}.
Of interest in this tutorial is @code{produce_effect} and the declaration of the @code{produce} output action:
@example
@verbatim
  int produce_effect () {
    int retval = m_count++;
    std::cout << "producing " << retval << std::endl;
    return retval;
  }

public:
  V_UP_OUTPUT (producer_automaton, produce, int);
@end verbatim
@end example
The @code{produce_effect} increments the counter and returns the old value of the counter.
The macro @code{V_UP_OUTPUT} declares a valued unparameterized output action named @code{produce} that produces a value of type @code{int}.
The @code{V_UP_OUTPUT} macro relies on the same naming conventions as the @code{UP_INTERNAL} action seen in preceding tutorials.
As an exercise, make the type given to @code{V_UP_OUTPUT} different from the type returned by @code{produce_effect}, e.g., change @code{int} to @code{float}, and recompile.
Note that @code{V_UP_OUTPUT} appears in a @code{public} section.
This is necessary because we want to allow other automata to bind to this action.

The @code{consumer_automaton} is quite simple and only contains a single valued unparameterized input action:
@example
@verbatim
  void consume_effect (const int& val) {
    std::cout << "consuming " << val << std::endl;
  }

  void consume_schedule () const { }

public:
  V_UP_INPUT (consumer_automaton, consume, int);
@end verbatim
@end example
Recall that I/O automata are input enabled so there is no @code{consume_precondition}.
The macro @code{V_UP_INPUT} declares a valued unparameterized input action named @code{consume} that takes a value of type @code{int}.
The @code{V_UP_INPUT} macro relies on the same naming conventions as the other macros.
The effect used by @code{V_UP_INPUT} must take a single argument declared as a constant reference.
Compare this with @code{consume_effect}.
Again, note that @code{V_UP_INPUT} appears in a @code{public} section so we can bind to it.

The @code{consume_schedule} function is required even though it is empty.
As an exercise, comment out the @code{consume_schedule} function and recompile to become familiar with the compilation error caused by omitting it.

The constructor of the @code{producer_consumer_automaton} creates a @code{producer_automaton} and a @code{consumer_automaton} and then binds the @code{produce} and @code{consume} actions of the respective automatons together:
@example
@verbatim
  producer_consumer_automaton () {
    ioa::automaton_manager<producer_automaton>* producer =
      ioa::make_automaton_manager (this,
	  ioa::make_generator<producer_automaton> ());

    ioa::automaton_manager<consumer_automaton>* consumer =
      ioa::make_automaton_manager (this,
          ioa::make_generator<consumer_automaton> ());

    ioa::make_binding_manager (this,
			       producer, &producer_automaton::produce,
			       consumer, &consumer_automaton::consume);
  }
@end verbatim
@end example
The child automata are created in the same way as in the preceding tutorials only we save the pointer to the new manager so we can pass it to the @code{ioa::make_binding_manager} function.
This version of @code{ioa::make_binding_manager} takes a pointer to an @code{ioa::automaton} (@pxref{Creating Automata}), a pointer to an @code{ioa::automaton_handle_interface} for the output automaton, a pointer to a member for the output action, a pointer to an @code{ioa::automaton_handle_interface} for the input automaton, and a pointer to a member for the input action.
The @code{ioa::automaton_handle_interface} is unimportant save to say that @code{ioa::automaton_manager} implements @code{ioa::automaton_handle_interface}.
The @code{ioa;:make_binding_manager} function creates a new @code{ioa::binding_manager} that binds the output and input actions once the output and input automata have been created.
Note that like automata creation, binding is asynchronous in ioa++.

@subsection Binding Rules

There are a number of rules that must be observed when binding.
The first set of rules are checked at compile time.
@enumerate
@item One Output, One Input --- The first automaton/action pair must be an output and the second automaton/action pair must be an input.

@item Access --- The output and input must be accessible from the scope where @code{ioa::make_binding_helper} is invoked.  For example, if automaton C is binding an output action in automaton O to an input action in automaton I, then both of the actions must be declared @code{public}.  As another example, if automaton C is binding one of its own output actions to an input in automaton I, then C can (and probably should) declare the output to be @code{private}.

@item Value Status Agreement --- External actions need not produce/consume values.  External actions that don't produce/consume values are called @dfn{unvalued} while external action that do produce/consume values are called @dfn{valued}.  When binding, both the output and the input action must have the same value status.

@item Type Agreement --- Valued external actions must agree on the same type.  For example, the @code{produce} action and @code{consume} action agree that the value being produced/consumed is an @code{int}.

@end enumerate
The second set of rules are checked at run time.
@enumerate
@item An input action can only be bound to one output action.
@item An output action cannot be bound to two different inputs residing in the same automaton.
@item An output action cannot be bound to an input action in the same automaton.
@end enumerate
These rules are necessary to adhere to the I/O automata model.
Recall that automata are composed by matching the names of output and input actions.
One could imagine a function that rewrites the names of all actions before composing.
These rules say that such a function exists.

@subsection Binding Dynamics

When I execute @code{producer_consumer}, I get the following output:
@example
@verbatim
$ ./producer_consumer 
producing 1
producing 2
producing 3
producing 4
producing 5
producing 6
producing 7
consuming 7
producing 8
consuming 8
producing 9
consuming 9
producing 10
consuming 10
@end verbatim
@end example
Recall that automata creation and binding is asynchronous.
In this example, the producer was allowed to @code{produce} six times before @code{produce} was bound to @code{consume}.
The @code{produce} action is a @dfn{lossy output} or an output whose values might be lost because no input is bound to receive them.
We address this topic in the next tutorial.

@node Fan-out and Binding Count
@section Fan-out and Binding Count

In this tutorial, we bind an output action to multiple input actions (fan-out) and prevent lost outputs by counting the number of bindings associated with an action.
The source is given below and can be found in @file{tutorial/producer_consumer2.cpp}.

@example
@verbatiminclude tutorial/producer_consumer2.cpp
@end example

The constructor of the @code{producer_consumer_automaton} creates a @code{producer_automaton} and two @code{consumer_automaton}s and then binds the @code{produce} and @code{consume} actions of the respective automatons together:
@example
@verbatim
  producer_consumer_automaton () {
    ioa::automaton_manager<producer_automaton>* producer =
      ioa::make_automaton_manager (this,
	  ioa::make_generator<producer_automaton> ());

    ioa::automaton_manager<consumer_automaton>* consumer1 =
      ioa::make_automaton_manager (this,
          ioa::make_generator<consumer_automaton> ());

    ioa::automaton_manager<consumer_automaton>* consumer2 =
      ioa::make_automaton_manager (this,
          ioa::make_generator<consumer_automaton> ());

    ioa::make_binding_manager (this,
			       producer, &producer_automaton::produce,
			       consumer1, &consumer_automaton::consume);

    ioa::make_binding_manager (this,
			       producer, &producer_automaton::produce,
			       consumer2, &consumer_automaton::consume);
  }
@end verbatim
@end example
We changed the @code{consume_effect} of the @code{consumer_automaton} to print out the aid to distinguish between the two consumers:
@example
@verbatim
  void consume_effect (const int& val) {
    std::cout << ioa::get_aid () << " consuming " << val << std::endl;
  }
@end verbatim
@end example
We also removed the call to @code{produce_schedule} in the @code{producer_automaton} constructor:
@example
@verbatim
  producer_automaton () :
    m_count (1) { }
@end verbatim
@end example
More on this later.

The most important change is the addition of an @code{ioa::binding_count} to the @code{produce_precondition} of the @code{producer} automaton:
@example
@verbatim
  bool produce_precondition () const {
    return m_count <= 10 &&
      ioa::binding_count (&producer_automaton::produce) == 2;
  }
@end verbatim
@end example
The @code{ioa::binding_count} returns the number of actions to which the given action is bound.
The binding count of an internal action will always be 0.
The binding count of an output action is a non-negative integer.
The binding count of an input action is either 0 or 1.
In this example, the @code{produce_effect} is not executed until the two consumers have been bound.

You might be wondering, ``If we don't schedule the @code{produce} action in the constructor, how does it get executed?''
The answer is that scheduler automatically schedules output actions when they are bound.
Thus, whenever the second automaton binds to @code{produce}, @code{produce} is scheduled.
Since the binding count is now 2, the @code{produce_precondition} becomes true, and @code{produce_effect} and @code{produce_schedule} are evaluated.
Scheduling output actions in this way takes advantage of the concept of a fair scheduler in the I/O automata model and seems to be a graceful way of handling the common case where an output must be bound before it is executed.

When I execute @code{producer_consumer2}, I get the following output:
@example
@verbatim
$ ./producer_consumer2
producing 1
3 consuming 1
4 consuming 1
producing 2
3 consuming 2
4 consuming 2
producing 3
3 consuming 3
4 consuming 3
producing 4
3 consuming 4
4 consuming 4
producing 5
3 consuming 5
4 consuming 5
producing 6
3 consuming 6
4 consuming 6
producing 7
3 consuming 7
4 consuming 7
producing 8
3 consuming 8
4 consuming 8
producing 9
3 consuming 9
4 consuming 9
producing 10
3 consuming 10
4 consuming 10
@end verbatim
@end example
which shows that both consumers receive the values produced by the producer.

@c Expected bind count in parameter

@c automatic parameters

@c self helper and binding

@c unbind

@c destroy

@c Show how to observe

@c Show how to self-destruct

@node Reference
@chapter Reference

@itemize
@item ioa::automaton
@item ioa::global_fifo_scheduler
@item ioa::run
@item ioa::make_generator
@item ioa::schedule
@item ioa::make_automaton_manager
@item ioa::automaton_manager
@item ioa::get_aid
@item ioa::aid_t
@item ioa::make_binding_manager
@item ioa::automaton_handle_interface
@item ioa::binding_manager
@item UV_UP_INPUT
@item UV_P_INPUT
@item UV_AP_INPUT
@item V_UP_INPUT
@item V_P_INPUT
@item V_AP_INPUT
@item UV_UP_OUTPUT
@item UV_P_OUTPUT
@item UV_AP_OUTPUT
@item V_UP_OUTPUT
@item V_P_OUTPUT
@item V_AP_OUTPUT
@item UP_INTERNAL
@item P_INTERNAL
@item SYSTEM_INPUT
@item SYSTEM_OUTPUT
@end itemize


@node Copying
@chapter Copying

@quotation
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
@end quotation

@c @node Index
@c @unnumbered Index

@c @printindex cp








@c @chapter Using the Formalism

@c @chapter Gotchas

@c @chapter Tips and Tricks


@c @section The Problem with Threads

@c The thread model dominates modern computing.
@c A @dfn{thread} consists of a sequence of instructions, state, and an instruction pointer indicating the location of the current instruction.
@c Conventional processors are a direct implementation of the thread model, mainstream compilers are designed to produce code for these processors, and modern operating systems are designed to execute programs on these processors.
@c Naturally, the application developed for these systems are also based on the thread model.

@c The dominance of the thread model makes it a practical choice for concurrency.
@c A physical processor can be multiplexed to execute multiple threads by repeatedly switching from one thread to another.
@c Multiple processors allow concurrent threads to execute simultaneously.
@c Concurrent threads communicate by sharing state and using synchronization primitives to control access to the state.
@c A section of code that updates shared state is called a @dfn{critical section}.

@c There are two main issues with using threads as a basis for concurrency.
@c The first is that reasoning about the correctness of a threaded program is notoriously difficult because one must consider all possible interleavings of critical sections.
@c System developers know that developing and debugging shared-state, lock-based programs is difficult.
@c Threads are also not composable.
@c One cannot combine the code for two threads into a single thread and reason about the behavior of the composition as the interactions of the two original threads.

@c The second issue is a diversity of threading techniques, resulting in systems that cannot easily be integrated.
@c Consider an application based on a reactive event loop that wishes to use a library that performs blocking I/O.
@c If the goal is to be responsive, the programmer must wrap all calls to the library as events and pass them to another thread to perform the blocking I/O.
@c The overhead of integration is often not negligible and tends to be a source of concurrency bugs.

@c @c In addition to the problems just mentioned, the clock frequencies of processors have reached a ceiling and processor manufacturers are looking to multi-core to deliver increased performance.
@c @c Gains in performance will only be realized through better data structures and algorithms, optimization, hardware acceleration, or concurrent computation.

@c @section The Search for Better Models

@c To ease the difficulties of developing systems with threads, practitioners and researchers have explored a number of options including new programming languages, language extensions, and libraries/frameworks/middleware/design patterns.
@c New programming languages and their run-time systems tend to not be adopted unless they resemble the language used to implement the operating system.
@c Consequently, C, C++, Java, and the like will dominate system programming languages for the foreseeable future.
@c Language extensions by their very definition are non-standard and therefore cannot be used to develop portable software.
@c Furthermore, concurrency is rather large and difficult piece to bolt on to an existing programming language.
@c Libraries, frameworks, middleware, and design patterns have been successful because they can take advantage of existing compilers and operating systems.
@c However, they tend to focus on domain-specific problems and lack generality in that sense.

@c I agree with Chris Gill's argument that the reason we have not found a better solution for concurrency is because we've been looking the wrong places.
@c Specifically, we've only considered domain-specific solutions that are all variations of the thread model.
@c I argue that a better place to look is the formal methods community.
@c The formal methods community has proposed a number of different models for concurrency, e.g., Petri nets, UNITY, I/O automata, all for the purpose of making reasoning about concurrency easier.
@c It stands to reason that a model that makes formal reasoning about concurrency easier will also make informal reasoning about concurrency easier.
@c What is lacking are implementations of these models that permit an honest evaluation.

@c Ideally, one would build a processor, programming language, operating system, and applications all based on Petri nets to evaluate the usefulness of Petri nets as a model of concurrency.
@c Cost and effort prohibit such a bottom-up approach.
@c Conversely, starting at the top and working down is a much better approach as many models can be tried with a smaller investment.
@c A model that succeeds can gradually sink from the application layer to the operating system layer.
@c Further subsuming is only necessary if a new programming language is need to make programming in the new model more efficient (for the machine or the programmer) or a new processor architecture based on the model provides significant advantages over existing processor architectures.

@c @section Scope

@c In pursuit of production grade implementations of different models of concurrency, @acronym{UEIOA} is an application level implementation of the I/O automata model.

@c @chapter Tutorial

@c @chapter Cookbook

@c @chapter Reference

@c @chapter Examples

@c @chapter FAQ

@c * Action Wrappers

@c   Sensing when an action changes binding status is useful.
@c   Consider a pair of automata, A and B, that are bound.
@c   If either one of them dies, the other should die.
@c   The automata can detect the death of the other by detecting when their respective actions are unbound.
@c   The Observer Pattern to the rescue again.
@c   We can make all input and output wrappers be observable so the automaton can know when something changes status.

@c The thread model is at the heart of modern computing as indicated by modern processors, programming languages, and operating systems.
@c A thread consists of 1) a sequence of instructions, 2) an instruction pointer indicating the current instruction, and 3) state that is manipulated by the instructions.
@c The current instruction and thread state including the instruction pointer determines the subsequent instruction pointer with the default being to advance to the next instruction.
@c All major processors are a direct realization of the thread model.
@c All major programming languages are based on the structured sequential programming paradigm which is defined using the thread abstraction.
@c All major operating systems are written using sequential languages and multiplex processors among different threads by periodically interrupting the current thread,  saving its instruction pointer and other processor state, and then loading and starting another thread.
@c Most modern applications are thread-based due to the strong agreement between the processor, programming language, and operating system.

@c # File System

@c The file system is a critical part of traditional operating systems.
@c If we use communication sequential processes, then we can model the virtual file system (or kernel) as a process that rendezvous with user processes at open, read, write, etc.

@c In an I/O Automata-based operating system, the file system is just another coordination mechanism.
@c From the bottom up, we can model physical disks as (physical) automata.
@c On top of the disks are file system drivers, e.g., ext, FAT, xfs, that are also automata.
@c On top of the disk drivers is the virtual file system automaton.
@c The virtual file system automaton creates file and directory automata with which users can interact.
@c Using I/O Automata to build a virtual file system has the potential to simplify certain features such as change notification and database triggers.  



@c Inputs

@c read
@c write

@c Ouputs

@c read_complete
@c write_complete
@c (We are asynchronous.  Consequently, we could take advantage of ASIO if it is available.  The complete calls allow us to have good back pressure (or flow control).)

@c Closing can be accomplished with an input or upon the first action unbind.



@c * Memory allocation
@c   The scheduler knows what automaton is running at any given time.
@c   Thus, we can associated allocated memory with an automaton and free it when the automaton is destroyed.




@c * Helpers

@c   System calls cannot be made while in the constructor of an automaton because the "this" pointer is not known to the scheduler and can't be used for certian sanity checks.
@c   So, the helpers have methods, create and bind respectively, that that get the helpers started.
@c   A starting point is to move all of the parameters required at construction to the appropriate start-up method.

@c   We desire (and have) the ability to create helpers dynamically, either directly (calling "new helper") or indirectly (calling "new object" where object contains one or more helpers).
@c   This gives us the power to create dynamic constellations of automata.
@c   However, they must be stopped before they are destroyed.
@c   To illustrate, consider the following sequence

@c   new automaton_helper
@c     create ->
@c     created <-              automaton
@c        |                        |
@c   delete automaton_helper       |
@c                                 |
@c                            delete automaton
@c     <-destroyed  [The system will call a non-existent callback.]
  
@c   Instead of calling delete, the sequence should contain a destroy/unbind call.
@c   The handler in the helper can then call delete to clean up.
@c   The new sequence looks like.

@c   new automaton_helper
@c     create ->
@c     created <-              automaton
@c        |                        |
@c   automaton_helper->destroy ()  |
@c        |                        |
@c        |                 delete automaton
@c     <-destroyed  [The helper will call "delete this" to clean the helper.]

@c   If the helper always calls delete, then we cannot have statically allocated helpers.
@c   This seems acceptable to me at this time.

@c   If we only allow dynamically allocated helpers, we can move all of the create/bind parameters back to the constructor and stipulate that the helpers are dynamically allocated at or after the init methods of the automaton.
@c   The helpers then have a very simple interface: a constructor and a destroy/unbind method.

@c   Suppose that an automaton has allocated some helpers is in its destructor.
@c   Also, suppose that the memory accounting framework does not exists (because it doesn't).
@c   The automaton designer, wishing to not introduce memory leaks, wishes to delete the helpers.
@c   However, the helper might have already been destroyed due to a callback resulting in a double-free.
@c   If we could guarantee that the helpers receive the appropriate destroyed/unbound signals before the destructor for the automaton, then the destructor doesn't need to delete the helpers.
@c   The system can (and does) enforce this.
@c   Otherwise, helpers become too complex and their utility is greatly diminished.
  
@c   We can group helpers into other objects to make the creation and maintenance of constellations easier.
@c   Initially, this looks difficult as it appears that we have the same problem as before, i.e., an automaton has no way of knowing when a grouping object is safe to delete.
@c   The Observer Pattern to the rescue.
@c   The helpers are observable, thus, the grouping object can observe them and know when they are all destroyed.
@c   If the group object itself is observable, then the automaton can know when the grouping object is defunct.
@c   The pattern can be repeated ad infinitum and resembles a tree structure with the automaton at the root, group objects at the branches, and helpers at the roots.
@c   In the tree, parents observe their children.


@c * Round-robin scheduler
@c   I would like to make a round-robin scheduler.
@c   Other scheduler's are also possible.


@c To write:
@c - Explain dispatching_automaton.
@c - UP_INTERNAL macros and underlying wrappers
@c - Why can't you do stuff in constructors?
@c - init ()
@c - helpers instead of the Big 4
@c - scheduling actions
@c - creation caveats = type safety
@c - Why is "this" everywhere?

@c @node Why I Created ioa++
@c @section Why I Created ioa++

@c ioa++ is a framework for asynchronous and concurrent computation based on the I/O automata model.
@c An I/O automaton is a set of state variables and atomic actions that manipulate the state variables.
@c I/O automata interact by associating an action in one automaton with an action in another.
@c The semantics of I/O automata are such that a set of interacting automata can analyzed as a single I/O automaton.
@c Consequently, ioa++ makes it possible to develop reusable modules for asynchronous and concurrent computation and assemble them to create complex systems.


@c The thread paradigm, a common approach to concurrency, is based on multiple concurrent threads of execution communicating via shared state.
@c Developing ``thread-safe'' software is difficult because developers must consider all possible interleavings of instructions and use locks to prevent bad program states.
@c (See @cite{The Problem with Threads} by Edward Lee for more information.)
@c Furthermore, assembling complex systems from thread-based modules can easily introduce concurrency hazards, e.g., creating a cycle in the graph of resource locks resulting in deadlock.

@c ioa++ is an alternative to threads.
@c The absence of shared state and the atomicity of each action obviate the need for locks and other concurrency control mechanisms in ioa++.


@c  and ad hoc event systems.

@c I created ioa++ so I could build distributed systems by assembling reusable concurrent and asynchronous modules.

@c Threads are an obvious first choice due to their widespread

@c I rejected threads because it is difficult to write thread-safe objects and assemble them into a working system.
@c Developing a thread-safe object is difficult because one must consider all possible interleavings of instructions.
@c The paper @cite{The Problem with Threads} by Edward Lee is a deeper exploration of this issue.
@c Assembling thread-safe objects can introduce concurrency hazards by, for example, creating a cycle in the graph of resource locks.

@c Events are 

@c The difficulties of thread-based development often 

@c Second, events, while matching the semantics of distributed systems, 

@c The difficulties with threads 


@c @node Considerations
@c @section Implementation Considerations

@c @subsection Scheduling

@c The only requirement that the I/O automata model places on the scheduler is fairness.
@c This is intentional as it reduces the number of assumptions that one needs to make about the environment.
@c The scheduler is assumed to be omniscient, i.e., it knows all of the actions and can find an action with a true precondition.
@c While implementing an omniscient scheduler is possible, it hinders the development of an efficient scheduler, i.e., one that avoids selecting actions whose precondition are false.
@c Consequently, the decision was made that the user is responsible for telling the scheduler which actions to consider.
@c The scheduler can implement different scheduling policies that influence the order in which actions are selected.
@c Again, the only requirement is that the scheduler is fair.

@c The act of telling the scheduler to consider an action for selection and execution is called @dfn{scheduling}.
@c If a user decides to schedule all actions all the time, then the scheduler degenerates into a brute-force omniscient scheduler.
@c A better approach has the user test the precondition of all actions and schedules those that are true.
@c The best approach has the user perform a dependency analysis to determine which actions could possibly enable other actions and then schedule the enabled actions.
@c Notice that this optimization is not possible unless users schedule the actions.
@c All of the examples in this document use the middle approach.

@bye
