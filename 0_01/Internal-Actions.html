<html lang="en">
<head>
<title>Internal Actions - The I/O Automata Library</title>
<meta http-equiv="Content-Type" content="text/html">
<meta name="description" content="The I/O Automata Library">
<meta name="generator" content="makeinfo 4.13">
<link title="Top" rel="start" href="index.html#Top">
<link rel="up" href="Tutorials.html#Tutorials" title="Tutorials">
<link rel="prev" href="Compiling-and-Linking.html#Compiling-and-Linking" title="Compiling and Linking">
<link href="http://www.gnu.org/software/texinfo/" rel="generator-home" title="Texinfo Homepage">
<!--
Copyright (C) 2011 Justin R. Wilson.

     This work is licensed under the Creative Commons
     Attribution-NoDerivs 3.0 Unported License. To view a copy of this
     license, visit http://creativecommons.org/licenses/by-nd/3.0/ or
     send a letter to Creative Commons, 444 Castro Street, Suite 900,
     Mountain View, California, 94041, USA.
   -->
<meta http-equiv="Content-Style-Type" content="text/css">
<style type="text/css"><!--
  pre.display { font-family:inherit }
  pre.format  { font-family:inherit }
  pre.smalldisplay { font-family:inherit; font-size:smaller }
  pre.smallformat  { font-family:inherit; font-size:smaller }
  pre.smallexample { font-size:smaller }
  pre.smalllisp    { font-size:smaller }
  span.sc    { font-variant:small-caps }
  span.roman { font-family:serif; font-weight:normal; } 
  span.sansserif { font-family:sans-serif; font-weight:normal; } 
--></style>
</head>
<body>
<div class="node">
<a name="Internal-Actions"></a>
<p>
Previous:&nbsp;<a rel="previous" accesskey="p" href="Compiling-and-Linking.html#Compiling-and-Linking">Compiling and Linking</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="Tutorials.html#Tutorials">Tutorials</a>
<hr>
</div>

<h3 class="section">2.2 Internal Actions</h3>

<p>In this tutorial we develop an automaton that counts to ten using an internal action. 
The source is given below and can be found in <samp><span class="file">tutorial/count_to_ten_automaton.cpp</span></samp>.

<pre class="example"><pre class="verbatim">     #include &lt;ioa/ioa.hpp>
     #include &lt;ioa/global_fifo_scheduler.hpp>
     
     // For std::cout.
     #include &lt;iostream>
     
     class count_to_ten_automaton :
       public ioa::automaton
     {
     private:
       int m_count;
     
     public:
       count_to_ten_automaton () :
         m_count (1)
       {
         schedule ();
       }
       
     private:
       bool increment_precondition () const {
         return m_count &lt;= 10;
       }
     
       void increment_effect () {
         std::cout &lt;&lt; m_count &lt;&lt; std::endl;
         ++m_count;
         schedule ();
       }
     
       UP_INTERNAL (count_to_ten_automaton, increment);
     
       void schedule () const {
         if (increment_precondition ()) {
           ioa::schedule (&amp;count_to_ten_automaton::increment);
         }
       }
     };
     
     int main () {
       ioa::global_fifo_scheduler sched;
       ioa::run (sched, ioa::make_generator&lt;count_to_ten_automaton> ());
       return 0; 
     }
     
</pre></pre>
   <p>The automata in this tutorial are listed in a way that attempts to mimic the style in <cite>Distributed Algorithms</cite>. 
In general, an automaton will have the following structure:
     <ul>
<li>Type definitions &mdash; Declare types that are used internally by the automaton (private) and types that are used by external actions (public).

     <li>State declarations &mdash; Declare the state variables of the automaton (private).

     <li>Constructors/Destructors &mdash; Declare/defined constructors to initialize the state variables and destructors to perform any required clean-up (public).

     <li>Actions &mdash; Declare/define the actions of the automaton.  Local actions consist of a precondition, a action body, and a member variable.  Input actions consist only of an action body.  Preconditions and actions bodies are declared private while the member variables can be declared public or private depending on their intended use.

     <li>Schedule and other member functions &mdash; Declare/define one or more functions for scheduling actions and useful functions for manipulating the state (private).

   </ul>

   <p>Let's examine the automaton section by section. 
The state of the automaton is declared with
<pre class="example"><pre class="verbatim">     private:
       int m_count;
</pre>
</pre>
   <p>In this case, the state of the automaton consists of a single integer <code>m_count</code>.

   <p>The count is initialized to 1 in the constructor:
<pre class="example"><pre class="verbatim">     public:
       count_to_ten_automaton () :
         m_count (1)
       {
         schedule ();
       }
</pre>
</pre>
   <p>The call to <code>schedule ()</code> will be explained later in the tutorial.

   <p>The automaton defines the precondition and effect for an unparameterized internal action named <code>increment</code> with
<pre class="example"><pre class="verbatim">     private:
       bool increment_precondition () const {
         return m_count &lt;= 10;
       }
     
       void increment_effect () {
         std::cout &lt;&lt; m_count &lt;&lt; std::endl;
         ++m_count;
         schedule ();
       }
</pre>
</pre>
   <p>Parameters are discussed in (TODO). 
Following the style in <cite>Distributed Algorithms</cite>, internal actions are divided into a <dfn>precondition</dfn> and <dfn>effect</dfn>. 
The precondition returns a Boolean indicating if the action can be executed. 
In this example, the precondition returns true so long as the count is less than or equal to ten. 
The pattern for declaring the precondition for an unparameterized internal actions is <code>bool </code><var>action-name</var><code>_precondition () const;</code>. 
Note that preconditions have the <code>const</code> modifier as they should not change the state of the automaton. 
The effect changes the state of the automaton. 
In this example, the effect prints the current value of the count, increments the count, and calles <code>schedule ()</code>. 
The pattern for declaring the effect of an unparameterized internal action is <code>void </code><var>action-name</var><code>_effect ();</code>.

   <p>The final part of declaring/defining an unparameterized internal action is to declare a member variable representing the action that dispatches to the precondition and effect and also contains appropriate typedefs for the scheduler. 
The is tedious so a set of a macros is defined to simplify declaring the members. 
The code
<pre class="example"><pre class="verbatim">       UP_INTERNAL (count_to_ten_automaton, increment);
</pre>
</pre>
   <p>uses the <code>UP_INTERNAL</code> macro to declare an action member variable <code>increment</code>. 
The macros rely on the <code>*_precondition</code> and <code>*_action</code> naming convention described earlier.

   <p>The final part of the automaton is a function that informs the scheduler what local actions to consider.
<pre class="example"><pre class="verbatim">       void schedule () const {
         if (increment_precondition ()) {
           ioa::schedule (&amp;count_to_ten_automaton::increment);
         }
       }
</pre>
</pre>
   <p>The action of <code>schedule ()</code> is straightforward:  it evaluates the precondition for increment and then schedules the increment action. 
It is good style to write one or more <code>schedule ()</code> functions and call them in the constructor and at the end of every action effect. 
A common source of errors is to either omit a local action from the <code>schedule ()</code> function or forget to call <code>schedule ()</code> in an action effect. 
As an exercise, comment out one or both of the calls to <code>schedule</code> and see what happens. 
It is important that none of the state variables change after the call to <code>schedule ()</code> so that the preconditions will be evaluated correctly.

   <p>To summarize, consider the uses of the automaton name and action names. 
To declare an automaton:
<pre class="example">     <code>class </code><var>automaton-name</var><code> : public ioa::automaton ...</code>
</pre>
   <p>To declare a precondition for an unparameterized internal action:
<pre class="example">     <code>bool </code><var>action-name</var><code>_precondition () const;</code>
</pre>
   <p>To declare a effect for an unparameterized internal action:
<pre class="example">     <code>void </code><var>action-name</var><code>_effect ();</code>
</pre>
   <p>To declare an unparameterized internal action:
<pre class="example">     <code>UP_INTERNAL (</code><var>automaton-name</var><code>, </code><var>action-name</var><code>);</code>
</pre>
   <p>To schedule an unparameterized local action:
<pre class="example">     <code>ioa::schedule (&amp;</code><var>automaton-name</var><code>::</code><var>action-name</var><code>);</code>
</pre>
   <!-- @section Automaton Helpers: Count-to-Ten Automata -->
<!-- Hiearchies -->
<!-- Automata helpers -->
<!-- get current id -->
<!-- @section External Actions: Cooperative Count-to-Ten -->
<!-- Input and output actions -->
<!-- Bind helpers -->
<!-- @section Advanced Topic: Parameters -->
<!-- Parameters -->
<!-- @section Advanced Topic: Automatic Parameters -->
<!-- automatic parameters -->
<!-- self helper -->
<!-- @node Index -->
<!-- @unnumbered Index -->
<!-- @printindex cp -->
<!-- @chapter Using the Formalism -->
<!-- @chapter Gotchas -->
<!-- @chapter Tips and Tricks -->
<!-- @section The Problem with Threads -->
<!-- The thread model dominates modern computing. -->
<!-- A @dfn{thread} consists of a sequence of instructions, state, and an instruction pointer indicating the location of the current instruction. -->
<!-- Conventional processors are a direct implementation of the thread model, mainstream compilers are designed to produce code for these processors, and modern operating systems are designed to execute programs on these processors. -->
<!-- Naturally, the application developed for these systems are also based on the thread model. -->
<!-- The dominance of the thread model makes it a practical choice for concurrency. -->
<!-- A physical processor can be multiplexed to execute multiple threads by repeatedly switching from one thread to another. -->
<!-- Multiple processors allow concurrent threads to execute simultaneously. -->
<!-- Concurrent threads communicate by sharing state and using synchronization primitives to control access to the state. -->
<!-- A section of code that updates shared state is called a @dfn{critical section}. -->
<!-- There are two main issues with using threads as a basis for concurrency. -->
<!-- The first is that reasoning about the correctness of a threaded program is notoriously difficult because one must consider all possible interleavings of critical sections. -->
<!-- System developers know that developing and debugging shared-state, lock-based programs is difficult. -->
<!-- Threads are also not composable. -->
<!-- One cannot combine the code for two threads into a single thread and reason about the behavior of the composition as the interactions of the two original threads. -->
<!-- The second issue is a diversity of threading techniques, resulting in systems that cannot easily be integrated. -->
<!-- Consider an application based on a reactive event loop that wishes to use a library that performs blocking I/O. -->
<!-- If the goal is to be responsive, the programmer must wrap all calls to the library as events and pass them to another thread to perform the blocking I/O. -->
<!-- The overhead of integration is often not negligible and tends to be a source of concurrency bugs. -->
<!-- @c In addition to the problems just mentioned, the clock frequencies of processors have reached a ceiling and processor manufacturers are looking to multi-core to deliver increased performance. -->
<!-- @c Gains in performance will only be realized through better data structures and algorithms, optimization, hardware acceleration, or concurrent computation. -->
<!-- @section The Search for Better Models -->
<!-- To ease the difficulties of developing systems with threads, practitioners and researchers have explored a number of options including new programming languages, language extensions, and libraries/frameworks/middleware/design patterns. -->
<!-- New programming languages and their run-time systems tend to not be adopted unless they resemble the language used to implement the operating system. -->
<!-- Consequently, C, C++, Java, and the like will dominate system programming languages for the foreseeable future. -->
<!-- Language extensions by their very definition are non-standard and therefore cannot be used to develop portable software. -->
<!-- Furthermore, concurrency is rather large and difficult piece to bolt on to an existing programming language. -->
<!-- Libraries, frameworks, middleware, and design patterns have been successful because they can take advantage of existing compilers and operating systems. -->
<!-- However, they tend to focus on domain-specific problems and lack generality in that sense. -->
<!-- I agree with Chris Gill's argument that the reason we have not found a better solution for concurrency is because we've been looking the wrong places. -->
<!-- Specifically, we've only considered domain-specific solutions that are all variations of the thread model. -->
<!-- I argue that a better place to look is the formal methods community. -->
<!-- The formal methods community has proposed a number of different models for concurrency, e.g., Petri nets, UNITY, I/O automata, all for the purpose of making reasoning about concurrency easier. -->
<!-- It stands to reason that a model that makes formal reasoning about concurrency easier will also make informal reasoning about concurrency easier. -->
<!-- What is lacking are implementations of these models that permit an honest evaluation. -->
<!-- Ideally, one would build a processor, programming language, operating system, and applications all based on Petri nets to evaluate the usefulness of Petri nets as a model of concurrency. -->
<!-- Cost and effort prohibit such a bottom-up approach. -->
<!-- Conversely, starting at the top and working down is a much better approach as many models can be tried with a smaller investment. -->
<!-- A model that succeeds can gradually sink from the application layer to the operating system layer. -->
<!-- Further subsuming is only necessary if a new programming language is need to make programming in the new model more efficient (for the machine or the programmer) or a new processor architecture based on the model provides significant advantages over existing processor architectures. -->
<!-- @section Scope -->
<!-- In pursuit of production grade implementations of different models of concurrency, @acronym{UEIOA} is an application level implementation of the I/O automata model. -->
<!-- @chapter Tutorial -->
<!-- @chapter Cookbook -->
<!-- @chapter Reference -->
<!-- @chapter Examples -->
<!-- @chapter FAQ -->
<!-- * Action Wrappers -->
<!-- Sensing when an action changes binding status is useful. -->
<!-- Consider a pair of automata, A and B, that are bound. -->
<!-- If either one of them dies, the other should die. -->
<!-- The automata can detect the death of the other by detecting when their respective actions are unbound. -->
<!-- The Observer Pattern to the rescue again. -->
<!-- We can make all input and output wrappers be observable so the automaton can know when something changes status. -->
<!-- The thread model is at the heart of modern computing as indicated by modern processors, programming languages, and operating systems. -->
<!-- A thread consists of 1) a sequence of instructions, 2) an instruction pointer indicating the current instruction, and 3) state that is manipulated by the instructions. -->
<!-- The current instruction and thread state including the instruction pointer determines the subsequent instruction pointer with the default being to advance to the next instruction. -->
<!-- All major processors are a direct realization of the thread model. -->
<!-- All major programming languages are based on the structured sequential programming paradigm which is defined using the thread abstraction. -->
<!-- All major operating systems are written using sequential languages and multiplex processors among different threads by periodically interrupting the current thread,  saving its instruction pointer and other processor state, and then loading and starting another thread. -->
<!-- Most modern applications are thread-based due to the strong agreement between the processor, programming language, and operating system. -->
<!-- # File System -->
<!-- The file system is a critical part of traditional operating systems. -->
<!-- If we use communication sequential processes, then we can model the virtual file system (or kernel) as a process that rendezvous with user processes at open, read, write, etc. -->
<!-- In an I/O Automata-based operating system, the file system is just another coordination mechanism. -->
<!-- From the bottom up, we can model physical disks as (physical) automata. -->
<!-- On top of the disks are file system drivers, e.g., ext, FAT, xfs, that are also automata. -->
<!-- On top of the disk drivers is the virtual file system automaton. -->
<!-- The virtual file system automaton creates file and directory automata with which users can interact. -->
<!-- Using I/O Automata to build a virtual file system has the potential to simplify certain features such as change notification and database triggers. -->
<!-- Inputs -->
<!-- read -->
<!-- write -->
<!-- Ouputs -->
<!-- read_complete -->
<!-- write_complete -->
<!-- (We are asynchronous.  Consequently, we could take advantage of ASIO if it is available.  The complete calls allow us to have good back pressure (or flow control).) -->
<!-- Closing can be accomplished with an input or upon the first action unbind. -->
<!-- * Memory allocation -->
<!-- The scheduler knows what automaton is running at any given time. -->
<!-- Thus, we can associated allocated memory with an automaton and free it when the automaton is destroyed. -->
<!-- * Helpers -->
<!-- System calls cannot be made while in the constructor of an automaton because the "this" pointer is not known to the scheduler and can't be used for certian sanity checks. -->
<!-- So, the helpers have methods, create and bind respectively, that that get the helpers started. -->
<!-- A starting point is to move all of the parameters required at construction to the appropriate start-up method. -->
<!-- We desire (and have) the ability to create helpers dynamically, either directly (calling "new helper") or indirectly (calling "new object" where object contains one or more helpers). -->
<!-- This gives us the power to create dynamic constellations of automata. -->
<!-- However, they must be stopped before they are destroyed. -->
<!-- To illustrate, consider the following sequence -->
<!-- new automaton_helper -->
<!-- create -> -->
<!-- created <-              automaton -->
<!-- |                        | -->
<!-- delete automaton_helper       | -->
<!-- | -->
<!-- delete automaton -->
<!-- <-destroyed  [The system will call a non-existent callback.] -->
<!-- Instead of calling delete, the sequence should contain a destroy/unbind call. -->
<!-- The handler in the helper can then call delete to clean up. -->
<!-- The new sequence looks like. -->
<!-- new automaton_helper -->
<!-- create -> -->
<!-- created <-              automaton -->
<!-- |                        | -->
<!-- automaton_helper->destroy ()  | -->
<!-- |                        | -->
<!-- |                 delete automaton -->
<!-- <-destroyed  [The helper will call "delete this" to clean the helper.] -->
<!-- If the helper always calls delete, then we cannot have statically allocated helpers. -->
<!-- This seems acceptable to me at this time. -->
<!-- If we only allow dynamically allocated helpers, we can move all of the create/bind parameters back to the constructor and stipulate that the helpers are dynamically allocated at or after the init methods of the automaton. -->
<!-- The helpers then have a very simple interface: a constructor and a destroy/unbind method. -->
<!-- Suppose that an automaton has allocated some helpers is in its destructor. -->
<!-- Also, suppose that the memory accounting framework does not exists (because it doesn't). -->
<!-- The automaton designer, wishing to not introduce memory leaks, wishes to delete the helpers. -->
<!-- However, the helper might have already been destroyed due to a callback resulting in a double-free. -->
<!-- If we could guarantee that the helpers receive the appropriate destroyed/unbound signals before the destructor for the automaton, then the destructor doesn't need to delete the helpers. -->
<!-- The system can (and does) enforce this. -->
<!-- Otherwise, helpers become too complex and their utility is greatly diminished. -->
<!-- We can group helpers into other objects to make the creation and maintenance of constellations easier. -->
<!-- Initially, this looks difficult as it appears that we have the same problem as before, i.e., an automaton has no way of knowing when a grouping object is safe to delete. -->
<!-- The Observer Pattern to the rescue. -->
<!-- The helpers are observable, thus, the grouping object can observe them and know when they are all destroyed. -->
<!-- If the group object itself is observable, then the automaton can know when the grouping object is defunct. -->
<!-- The pattern can be repeated ad infinitum and resembles a tree structure with the automaton at the root, group objects at the branches, and helpers at the roots. -->
<!-- In the tree, parents observe their children. -->
<!-- * Round-robin scheduler -->
<!-- I would like to make a round-robin scheduler. -->
<!-- Other scheduler's are also possible. -->
<!-- To write: -->
<!--  Explain dispatching_automaton. -->
<!--  UP_INTERNAL macros and underlying wrappers -->
<!--  Why can't you do stuff in constructors? -->
<!--  init () -->
<!--  helpers instead of the Big 4 -->
<!--  scheduling actions -->
<!--  creation caveats = type safety -->
<!--  Why is "this" everywhere? -->
</body></html>

